{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1qPNluzyBHWR"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install rdkit\n",
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "from math import sqrt\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, Draw, PandasTools, Descriptors\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import random_split, SubsetRandomSampler\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.utils import to_networkx\n",
        "from torch_geometric.nn import AttentiveFP\n",
        "\n",
        "import os\n",
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "\n",
        "from torch_geometric.data import InMemoryDataset, download_url, extract_gz\n",
        "from torch_geometric.utils import from_smiles\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "jOGhYkhhtBKy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_set(seed=50):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)"
      ],
      "metadata": {
        "id": "7FxuMYkqtJuN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_set()"
      ],
      "metadata": {
        "id": "jTYipGRjtNlJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final = pd.read_csv('Lipophilicity_final.csv')\n",
        "\n",
        "graph_list = []\n",
        "for i, smile in enumerate(df_final['smiles']):\n",
        "  g = from_smiles(smile)\n",
        "  g.x = g.x.float()\n",
        "  y = torch.tensor(df_final['exp'][i], dtype=torch.float).view(1, -1)\n",
        "  g.y = y\n",
        "  graph_list.append(g)\n"
      ],
      "metadata": {
        "id": "yG5lagzAtOio"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Define Model**"
      ],
      "metadata": {
        "id": "Y82XH_7QuJlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = AttentiveFP(in_channels=9, hidden_channels=64, out_channels=1,\n",
        "                    edge_dim=3, num_layers=4, num_timesteps=2,\n",
        "                    dropout=0.2).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=10**-2.5,\n",
        "                             weight_decay=10**-5)"
      ],
      "metadata": {
        "id": "AC_QMz3ytZl_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Train and Test Functions**"
      ],
      "metadata": {
        "id": "LyLeIc_8uFG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    total_loss = total_samples = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
        "        loss = F.mse_loss(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * data.num_graphs\n",
        "        total_samples += data.num_graphs\n",
        "    return sqrt(total_loss / total_samples)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(loader):\n",
        "    mse = []\n",
        "    model.eval()\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data.x, data.edge_index, data.edge_attr,data.batch)\n",
        "        l = F.mse_loss(out, data.y, reduction='none').cpu()\n",
        "        mse.append(l)\n",
        "    rmse = float(torch.cat(mse, dim=0).mean().sqrt())\n",
        "    return rmse\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval(loader):\n",
        "    output = []\n",
        "    smi = []\n",
        "    model.eval()\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
        "        concatenated_data = torch.cat((out, data.y.view(-1, 1)), dim=1)\n",
        "        output.append(concatenated_data)\n",
        "        smi.append(data.smiles)\n",
        "\n",
        "    # Stack the tensors along batch dimension\n",
        "    stacked_output = torch.cat(output, dim=0)\n",
        "    stacked_smiles = np.concatenate(smi)\n",
        "    results = pd.concat([pd.DataFrame(stacked_output, columns=['pred', 'actual']), pd.DataFrame(stacked_smiles, columns=['smiles'])], axis=1)\n",
        "    r2 = r2_score(results['actual'], results['pred'])\n",
        "    print(f\"The R2 score for {fold} epoch is {r2}\")\n",
        "    return r2"
      ],
      "metadata": {
        "id": "8OmlqQPctmln"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Cross-Validation**"
      ],
      "metadata": {
        "id": "8ULgUPwYufu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=5, shuffle=True, random_state=50)\n",
        "for fold, (train_ids, test_ids) in enumerate(kfold.split(graph_list)):\n",
        "  print(train_ids)\n",
        "  print(len(train_ids))\n",
        "  print(len(test_ids))\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGqnHNPq_idN",
        "outputId": "0309e320-aff0-4a47-d2f7-ace500a7b5c2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   0    1    2 ... 4189 4190 4191]\n",
            "3353\n",
            "839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "  # Configuration options\n",
        "  k_folds = 5\n",
        "  epochs = 75\n",
        "\n",
        "  # For fold results\n",
        "  results = []\n",
        "\n",
        "  # Define the K-fold Cross Validator\n",
        "  kfold = KFold(n_splits=k_folds, shuffle=True, random_state=50)\n",
        "\n",
        "  # Start print\n",
        "  print('--------------------------------')\n",
        "\n",
        "  # K-fold Cross Validation model evaluation\n",
        "  for fold, (train_ids, test_ids) in enumerate(kfold.split(graph_list)):\n",
        "\n",
        "    # Print\n",
        "    print(f'FOLD {fold}')\n",
        "    print('--------------------------------')\n",
        "\n",
        "    # Sample elements randomly from a given list of ids, no replacement.\n",
        "    train_subsampler = SubsetRandomSampler(train_ids)\n",
        "    test_subsampler = SubsetRandomSampler(test_ids)\n",
        "\n",
        "    train_loader = DataLoader(graph_list, batch_size=32, sampler=train_subsampler)\n",
        "\n",
        "    test_loader = DataLoader(graph_list, batch_size=32, sampler=test_subsampler)\n",
        "\n",
        "    model.reset_parameters()\n",
        "    for epoch in range(epochs):\n",
        "        train_rmse = train()\n",
        "        test_rmse = test(test_loader)\n",
        "        if epoch%15 == 0:\n",
        "          print(f'Epoch: {epoch:03d}, Train Loss: {train_rmse:.4f} '\n",
        "              f'Test Loss: {test_rmse:.4f}')\n",
        "    # Process is complete.\n",
        "    print('Training process has finished. Saving trained model.')\n",
        "\n",
        "    # Print about testing\n",
        "    print('Starting testing')\n",
        "\n",
        "    # Saving the model\n",
        "    save_path = f'/content/model-fold-{fold}.pth'\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    results.append(eval(test_loader))\n",
        "\n",
        "# Print fold results\n",
        "print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
        "print('--------------------------------')\n",
        "print(f'Average test {k_folds} fold cross-val r2: {sum(results)/len(results)}')"
      ],
      "metadata": {
        "id": "7FfvUivMuPXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zsQ-tQprx8gd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}