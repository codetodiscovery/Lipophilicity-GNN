{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "opLI1q_oJxr-"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install torch_geometric\n",
        "!pip install rdkit\n",
        "!pip install --quiet optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "\n",
        "from math import sqrt\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import AttentiveFP\n",
        "\n",
        "import os\n",
        "from torch_geometric.utils import from_smiles\n",
        "from torch_geometric.loader import DataLoader"
      ],
      "metadata": {
        "id": "L5hHfs-SJ--w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_set(seed=50):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "seed_set()"
      ],
      "metadata": {
        "id": "1jPQb1ugKDKR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final = pd.read_csv('Lipophilicity_final.csv')\n",
        "\n",
        "graph_list = []\n",
        "for i, smile in enumerate(df_final['smiles']):\n",
        "  g = from_smiles(smile)\n",
        "  g.x = g.x.float()\n",
        "  y = torch.tensor(df_final['exp'][i], dtype=torch.float).view(1, -1)\n",
        "  g.y = y\n",
        "  graph_list.append(g)\n"
      ],
      "metadata": {
        "id": "FnCTqnD1KDym"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.80  # 80% for training, 20% for testing\n",
        "dataset_size = len(graph_list)\n",
        "train_size = int(train_ratio * dataset_size)\n",
        "test_size = dataset_size - train_size"
      ],
      "metadata": {
        "id": "H_EYjf1HKIHS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    # Define hyperparameters to be tuned\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=False)\n",
        "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-3, log=False)\n",
        "    dropout = trial.suggest_float('dropout', 0.0, 0.5, step = 0.1)\n",
        "    num_layers = trial.suggest_int('num_layers', 2, 6)\n",
        "    hidden_channels = trial.suggest_int('hidden_channels', 32, 192, step=32)\n",
        "    # optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
        "    batch_size = trial.suggest_int('batch_size', 16, 128, step=16)\n",
        "\n",
        "    # Split the dataset into train and test subsets\n",
        "    generator1 = torch.Generator().manual_seed(42)\n",
        "    train_dataset, test_dataset = random_split(graph_list, [train_size, test_size], generator=generator1)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    model = AttentiveFP(in_channels=9, hidden_channels=hidden_channels, out_channels=1,\n",
        "                        edge_dim=3, num_layers=num_layers, num_timesteps=2,\n",
        "                        dropout=dropout).to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr,\n",
        "                                weight_decay=weight_decay)\n",
        "\n",
        "\n",
        "    # Training loop\n",
        "\n",
        "    def train():\n",
        "        total_loss = total_examples = 0\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
        "            loss = F.mse_loss(out, data.y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += float(loss) * data.num_graphs\n",
        "            total_examples += data.num_graphs\n",
        "        return sqrt(total_loss / total_examples)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def test(loader):\n",
        "        mse = []\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            out = model(data.x, data.edge_index, data.edge_attr,data.batch)\n",
        "            l = F.mse_loss(out, data.y, reduction='none').cpu()\n",
        "            mse.append(l)\n",
        "        rmse = float(torch.cat(mse, dim=0).mean().sqrt())\n",
        "        return rmse\n",
        "\n",
        "    for epoch in range(75):\n",
        "        train_rmse = train()\n",
        "        test_rmse = test(test_loader)\n",
        "\n",
        "        trial.report(test_rmse, epoch)\n",
        "\n",
        "        # Handle pruning based on the intermediate value.\n",
        "        if trial.should_prune():\n",
        "            raise optuna.TrialPruned()\n",
        "\n",
        "    return test_rmse"
      ],
      "metadata": {
        "id": "fRoSLmrwKKtS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a study object and optimize the objective function\n",
        "study = optuna.create_study(direction='minimize',\n",
        "                            study_name = 'hyperparameter-tune-afp',\n",
        "                            storage = 'sqlite:///htune_afp.db'\n",
        "                            )\n",
        "study.optimize(objective, n_trials=100)\n"
      ],
      "metadata": {
        "id": "0CukxoudKO6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.load_study(study_name='hyperparameter-tune-afp', storage=\"sqlite:///htune_afp.db\")"
      ],
      "metadata": {
        "id": "EpaeX0hWFsJg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = study.best_params\n",
        "print(\"Best hyperparameters:\", best_params)\n",
        "\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYsc1G-rKSVM",
        "outputId": "a527b5dd-5d56-47d8-b1a7-0c2968fd272a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'lr': 0.001867322759986135, 'weight_decay': 0.0003126662000605776, 'dropout': 0.0, 'num_layers': 6, 'hidden_channels': 64, 'batch_size': 96}\n",
            "Study statistics: \n",
            "  Number of finished trials:  100\n",
            "  Number of pruned trials:  75\n",
            "  Number of complete trials:  25\n",
            "Best trial:\n",
            "  Value:  0.6075412631034851\n",
            "  Params: \n",
            "    lr: 0.001867322759986135\n",
            "    weight_decay: 0.0003126662000605776\n",
            "    dropout: 0.0\n",
            "    num_layers: 6\n",
            "    hidden_channels: 64\n",
            "    batch_size: 96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZhIomrbYD7qE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}